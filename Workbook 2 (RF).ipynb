{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing processing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio as rio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from osgeo import gdal\n",
    "from osgeo import gdal_array\n",
    "from osgeo import osr\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Workspace path \n",
    "os.chdir(r\"C:\\Thesis_data\\Data\\working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing setup assessment and initial data \n",
    "##### Processing Parameters  \n",
    "Changing Parameters from TRUE to FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_vegetation_indices =True\n",
    "use_hyperparameter_tuning =False\n",
    "use_oversampling=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('Train_split_70_resampled.csv')\n",
    "print('We have {} train data with {} variables'.format(*train_features.shape))\n",
    "test_features = pd.read_csv('Test_split_30_resampled.csv')\n",
    "print('We have {} test data with {} variables'.format(*test_features.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Process\n",
    "<blockquote><b>RF</b><br>Random forest processing steps it starts with predicting and finding the accuracy and trying different options such as <b>using oversampling</b>, using <b>hyperparameter tuning</b> and <b>Vegetation indices</b> the result of each option has been provided below</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Extracting value for test and train dataset for randomforest assessment</b><br>\n",
    "<b>Training process without considering different indices</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if  use_vegetation_indices == True: \n",
    "    # included vegetation indices\n",
    "    X_train = train_features.iloc[:,2:]\n",
    "    y_train = train_features.iloc[:,0]\n",
    "    X_test = test_features.iloc[:,2:]\n",
    "    y_test = test_features.iloc[:,0]\n",
    "\n",
    "else:\n",
    "    # Included DSM\n",
    "    X_train = train_features.iloc[:,2:6]\n",
    "    y_train = train_features.iloc[:,0]\n",
    "    X_test = test_features.iloc[:,2:6]\n",
    "    y_test = test_features.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Features Shape:', X_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', X_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_oversampling == True:\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "print('Resampled train dataset shape %s' % Counter(y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training  model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_hyperparameter_tuning == True:\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    parameters={\"n_estimators\":[100, 200],\n",
    "              \"max_depth\":[3, 5, 6, 9, 15], 'min_samples_split': [11, 15, 19], \n",
    "              'min_samples_leaf': [3,5,7], \"bootstrap\":[True,False],\"max_features\":['auto']}\n",
    "    grid_rf = GridSearchCV(rf, param_grid = parameters, cv = 3, n_jobs = -2)\n",
    "    grid_rf.fit(X_train, y_train)\n",
    "    scores_df = pd.DataFrame(grid_rf.cv_results_) #scores_df = pd.DataFrame(grid_rf.cv_results_)\n",
    "    best_param=grid_rf.best_params_ #best=grid_rf.best_params_\n",
    "    print(\"Best paramters :\", grid_rf.best_params_)\n",
    "    print(\"Best accuracy scores for train data:\", grid_rf.best_score_)\n",
    "    pred = grid_rf.predict(X_test)# Prediction\n",
    "    Accuracy_hyperparameter =accuracy_score(pred,y_test)\n",
    "    print(\"Accuracy score based on test data with Hyperparameter tuning\",round(metrics.accuracy_score(pred,y_test)*100,2), '%.')\n",
    "    print(classification_report(y_test,pred))\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    print(\"Confusion Metrix:\\n\",metrics.confusion_matrix(pred,y_test))\n",
    "    cm = metrics.confusion_matrix(pred,y_test)\n",
    "    plot_confusion_matrix(grid_rf, X_test, y_test ,  ax=ax,cmap=plt.cm.YlGnBu)\n",
    "    plt.title('Confusion matrix RF hyperparameter model')\n",
    "    plt.savefig(\"figure2.png\") \n",
    "    plt.show()\n",
    "    #normalize='true'\n",
    "\n",
    "else:\n",
    "    rf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "                                max_features='auto',random_state=42,max_samples=None)\n",
    "    #learning\n",
    "    rf.fit(X_train,y_train)\n",
    "    #Prediction\n",
    "    prediction=rf.predict(X_test)\n",
    "    #evaluation(Accuracy)\n",
    "    #Accuracy_base_model= accuracy_score(prediction,y_test)\n",
    "    Accuracy_base_model= accuracy_score(prediction,y_test)\n",
    "    print(\"Accuracy score based on test data without Hyperparameter tuning\",round(metrics.accuracy_score(prediction,y_test)*100,2), '%.')\n",
    "    #evaluation(Confusion Metrix)\n",
    "    print(classification_report(y_test,prediction,zero_division=0))\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    plot_confusion_matrix(rf, X_test, y_test ,  ax=ax,cmap=plt.cm.YlGnBu)\n",
    "    print(\"Confusion Metrix:\\n\",metrics.confusion_matrix(prediction,y_test))\n",
    "    cm = metrics.confusion_matrix(prediction,y_test)\n",
    "    plt.title('Confusion matrix of Random forest model')\n",
    "    plt.savefig(\"figure.png\") \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampled orthophoto UAV by the model with higher accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the resampled (121 pixels) raster data\n",
    "raster_filename = \"Ortho_compelete_resampled.tif\"\n",
    "DSM=\"dsm_re.tif\"\n",
    "GLI=\"GLI_resampled.tif\"\n",
    "VARI=\"Vari_resampled.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rio.open(raster_filename)\n",
    "dsm=rio.open(DSM)\n",
    "vari=rio.open(VARI)\n",
    "gli=rio.open(GLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the raster values\n",
    "band1 = dataset.read(1)\n",
    "band2=dataset.read(2)\n",
    "band3=dataset.read(3)\n",
    "dsm2 = dsm.read(1)\n",
    "vari2 = vari.read(1)\n",
    "gli2=gli.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting 2D numpy array to 1d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RGB values \n",
    "one=band1.flatten() \n",
    "two=band2.flatten() \n",
    "three=band3.flatten()\n",
    "one_data= pd.DataFrame(one)\n",
    "two_data= pd.DataFrame(two)\n",
    "th_data= pd.DataFrame(three)\n",
    "dataframe_rgb=pd.concat([one_data,two_data,th_data], axis=1)\n",
    "dataframe_rgb.columns =['red', 'blue', 'green']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DSM & GLI & VARI\n",
    "dsm2_r = dsm2.flatten()   \n",
    "vari2_r = vari2.flatten()\n",
    "gli2_r = gli2.flatten()\n",
    "df1=pd.DataFrame(dsm2_r)\n",
    "df2=pd.DataFrame(vari2_r)\n",
    "df3=pd.DataFrame(gli2_r)\n",
    "indices=pd.concat([df1,df3,df2], axis=1)\n",
    "indices.columns =['DSM','GLI', 'VARI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the dataframe of resampled data\n",
    "Making the simliar dataframe to the main dataframe for prediction of labels of each pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe2=pd.concat([dataframe_rgb,indices], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe2.loc[(dataframe2.red== 0.0) & (dataframe2.blue== 0.0) & (dataframe2.green== 0.0),'DSM']=0.0\n",
    "dataframe2.loc[(dataframe2.red== 0.0) & (dataframe2.blue== 0.0) & (dataframe2.green== 0.0) ,'GLI']=0.0\n",
    "dataframe2.loc[(dataframe2.red== 0.0) & (dataframe2.blue== 0.0) & (dataframe2.green== 0.0),'VARI']=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction of  each pixels labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1=rf.predict(dataframe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = pd.Series(prediction1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe1=pd.concat([dataframe2,labels1], axis=1)\n",
    "dataframe1.rename(columns={0: 'labels'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dataframe1['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe1.loc[(dataframe1.red== 0.0) & (dataframe1.blue== 0.0) & (dataframe1.green== 0.0),'labels']=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe1['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= dataframe1['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of final classified map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors\n",
    "raster = np.ndarray(shape=(10,20), dtype=np.float32)\n",
    "raster=labels.values.reshape(4575,3786)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(10,10))\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", ['w','dodgerblue','forestgreen','darkkhaki','olivedrab','khaki','seagreen','yellowgreen','brown'])\n",
    "#['w','dodgerblue','forestgreen','darkkhaki','olivedrab','y','seagreen','yellowgreen','brown'])\n",
    "plt.imshow(raster,cmap=cmap)\n",
    "c=plt.colorbar(ticks=range(9), label='landcover classes ')\n",
    "c.ax.set_yticklabels(['Background','1: Water', '2:Pinus', ' 3: Betula','4:Rhynchospora','5:Phragmites','6: Eriphorum','7:Carex','8:Barepeat'])\n",
    "plt.title('The reclassified map of study area with RF classifier')\n",
    "plt.savefig(\"test.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=raster\n",
    "xmin,ymin,xmax,ymax = [521300.8197345125372522,6494659.9188134595751762,\n",
    "                       522491.9864475125796162,6496099.11398845911] #meters (obtained with a conversion)\n",
    "nrows,ncols = np.shape(array)\n",
    "xres = (xmax-xmin)/float(ncols)\n",
    "yres = (ymax-ymin)/float(nrows)\n",
    "geotransform=(xmin,xres,0,ymax,0, -yres) \n",
    "output_raster = gdal.GetDriverByName('GTiff').Create('final_test.tif',ncols, nrows, 1 ,gdal.GDT_Float32)\n",
    "#writting output raster\n",
    "output_raster.GetRasterBand(1).WriteArray( array ) \n",
    "output_raster.SetGeoTransform(geotransform)\n",
    "srs = osr.SpatialReference()\n",
    "srs.ImportFromEPSG(3301) \n",
    "output_raster.SetProjection(srs.ExportToWkt())\n",
    "output_raster = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.savefig('finalmap.png')\n",
    "plt.savefig(\"finalmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting the number of True and False predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_features.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(data=prediction)\n",
    "df1.rename(columns={0: 'PL'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col = pd.concat([df, df1],axis = 1)\n",
    "#path=r\"C:\\Thesis_data\\Data\\working\"\n",
    "#Half = os.path.join(path,'Half.csv')\n",
    "#df_col.to_csv(Half, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare = np.where(df_col['PL'] == df_col['Class'], 'True', 'False')\n",
    "df_compare=pd.DataFrame(data=df_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df_compare, df_col],axis = 1)\n",
    "df3.rename(columns={0: 'lables'}, inplace=True)\n",
    "df3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df3['PL'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df3['lables'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class = pd.DataFrame(df3.groupby('lables').size())\n",
    "ax = df3.lables.value_counts()\n",
    ".plot(kind='barh', title=\"Predicted lables of test data \",color='red')\n",
    "ax.set_xlabel(\"Predicted lables\")\n",
    "ax.set_ylabel(\"Count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
